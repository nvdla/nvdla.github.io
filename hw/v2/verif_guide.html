<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>NVDLA Verification Suite User Guide &#8212; NVDLA Documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/nvdla.css?v=907781f7" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles.css?v=af91e327" />
    <script src="../../_static/documentation_options.js?v=7026087e"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Software Manual" href="../../sw/contents.html" />
    <link rel="prev" title="Scalability parameters and ConfigROM" href="scalability.html" />
 
<style>
  #onetrust-banner-sdk.otFloatingRounded {
    margin-left:-10px !important;
    margin-bottom:-10px !important;
    width: 100% !important;
    max-width: 100% !important;
  }
</style>
<script src="https://assets.adobedtm.com/5d4962a43b79/814eb6e9b4e1/launch-4bc07f1e0b0b.min.js"></script>
<!-- OneTrust Cookies Consent Notice start for nvidia.com -->
<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="3e2b62ff-7ae7-4ac5-87c8-d5949ecafff5-test" ></script>
<script type="text/javascript">
function OptanonWrapper() {
        var event = new Event('bannerLoaded');
        window.dispatchEvent(event);
    }
</script>
<!-- OneTrust Cookies Consent Notice end for nvidia.com -->
 <script type="text/javascript" src="https://images.nvidia.com/aem-dam/Solutions/ot-js/ot-custom.js"></script>
  </head><body>
<header class="navbar">
  <nav class="container navbar navbar-light bg-faded">
    <a class="navbar-brand" href="https://www.nvidia.com/">
      <div class="logo"></div>
    </a>
  </nav>
</header>

    <div class="related" role="navigation" aria-label="related navigation">
      <div class="container">
      <div class="row">
      <h3>Navigation</h3>
      <ul>
        <li class="right first">
          <a href="../../sw/contents.html" title="Software Manual"
             accesskey="N">next</a></li>
        <li class="right">
          <a href="scalability.html" title="Scalability parameters and ConfigROM"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">NVDLA Open Source Project</a>&#187;</li>
        <li class="nav-item nav-item-1"><a href="../../contents.html">Documentation</a>&#187;</li>
          <li class="nav-item nav-item-2"><a href="../contents.html" accesskey="U">Hardware Manual</a>&#187;</li> 
      </ul>
      </div>
      </div>
    </div>
  <div class="document">
    <div class="container">
      <div class="row">
        <div class="col-xs-12 col-md-9">
          
  <section id="nvdla-verification-suite-user-guide">
<h1><a class="toc-backref" href="#id3" role="doc-backlink">NVDLA Verification Suite User Guide</a><a class="headerlink" href="#nvdla-verification-suite-user-guide" title="Link to this heading">¶</a></h1>
<nav class="contents" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#nvdla-verification-suite-user-guide" id="id3">NVDLA Verification Suite User Guide</a></p>
<ul>
<li><p><a class="reference internal" href="#preparation" id="id4">Preparation</a></p>
<ul>
<li><p><a class="reference internal" href="#acronym" id="id5">Acronym</a></p></li>
<li><p><a class="reference internal" href="#setup-tree-make-and-build-tree" id="id6">Setup tree.make and Build tree</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#quick-start" id="id7">Quick Start</a></p>
<ul>
<li><p><a class="reference internal" href="#running-single-test" id="id8">Running single test</a></p></li>
<li><p><a class="reference internal" href="#running-a-list-of-tests" id="id9">Running a list of tests</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#verification-suite" id="id10">Verification Suite</a></p>
<ul>
<li><p><a class="reference internal" href="#test-bench-architecture" id="id11">Test Bench Architecture</a></p></li>
<li><p><a class="reference internal" href="#test-plan" id="id12">Test Plan</a></p></li>
<li><p><a class="reference internal" href="#test-suite" id="id13">Test Suite</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#regression-tool-set" id="id14">Regression Tool Set</a></p>
<ul>
<li><p><a class="reference internal" href="#running-a-single-test" id="id15">Running a Single Test</a></p></li>
<li><p><a class="reference internal" href="#running-a-test-plan" id="id16">Running a Test Plan</a></p></li>
<li><p><a class="reference internal" href="#generating-reporting-metrics" id="id17">Generating Reporting Metrics</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
<section id="preparation">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Preparation</a><a class="headerlink" href="#preparation" title="Link to this heading">¶</a></h2>
<section id="acronym">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">Acronym</a><a class="headerlink" href="#acronym" title="Link to this heading">¶</a></h3>
<p>Following acronyms will be frequently used in this document, if there
are abbreviations you don’t know their meanings, please check this
chapter.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Acronym</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>tree</p></td>
<td><p>Repository hosting NVDLA source
code</p></td>
</tr>
<tr class="row-odd"><td><p>TOT</p></td>
<td><p>Top of Tree, refer to the root of
NVDLA HW repository nvdla/hw</p></td>
</tr>
<tr class="row-even"><td><p>OUTDIR</p></td>
<td><p>Generated code under TOT/ourdir</p></td>
</tr>
<tr class="row-odd"><td><p>Sub-unit</p></td>
<td><p>A module which has a dedicated
register block. For example,
CDMA/CSC/CMAC/CACC/SDP/SDP_RDMA
are all sub-units.</p></td>
</tr>
<tr class="row-even"><td><p>Resource</p></td>
<td><p>Hardware operation resources. One
resource may contain one or more
sub-units.</p>
<p>For example, a combination of
CSC/CMAC/CACC is one resource.
SDP_RDMA and SDP are two
independent resources.</p>
</td>
</tr>
<tr class="row-odd"><td><p>Hardware pipeline</p></td>
<td><p>A combination of resources for a
specified operation.</p>
<p>A hardware pipeline starts with
one or more read DMA(s) and ends
with one write DMA.</p>
</td>
</tr>
<tr class="row-even"><td><p>Scenario</p></td>
<td><p>A description of hardware
pipelines.</p></td>
</tr>
<tr class="row-odd"><td><p>HWL/HW layer</p></td>
<td><p>One complete hardware processing
within a hardware pipeline.</p>
<p>A hardware layer starts with a
set of register configuration
with an enable field. When it’s
done, it triggers ONE interrupt.</p>
<p>A hardware layer requires a
hardware pipeline.</p>
</td>
</tr>
<tr class="row-even"><td><p>Image data</p></td>
<td><p>The input data of convolution HW
layer.</p>
<p>In convolution, image data is the
station operand.</p>
</td>
</tr>
<tr class="row-odd"><td><p>Feature data</p></td>
<td><p>The input/output data of
HW-layer.</p>
<p>Feature data is generated from
one HW-layer and can be used as
input data for next HW-layer.</p>
<p>In convolution, feature data is
the station operand.</p>
</td>
</tr>
<tr class="row-even"><td><p>Weight data</p></td>
<td><p>The moving operand of convolution
operation.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="setup-tree-make-and-build-tree">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">Setup tree.make and Build tree</a><a class="headerlink" href="#setup-tree-make-and-build-tree" title="Link to this heading">¶</a></h3>
<p>Please follow instructions in <a class="reference internal" href="environment_setup_guide.html"><span class="doc">NVDLA Environment Setup Guide</span></a>, section
<em>Tools and Dependency Libraries Setup</em> to setup environment and section
<em>Build Test Bench</em> to build test bench before advancing to next section.</p>
</section>
</section>
<section id="quick-start">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Quick Start</a><a class="headerlink" href="#quick-start" title="Link to this heading">¶</a></h2>
<p>After tree was built, we can run a test and a regression to validate
NVDLA environment is in good health.</p>
<p>Let’s create a directory named health_exam.</p>
<p><code class="docutils literal notranslate"><span class="pre">TOT&gt;</span> <span class="pre">mkdir</span> <span class="pre">health_exam</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">TOT&gt;</span> <span class="pre">cd</span> <span class="pre">health_exam</span></code></p>
<section id="running-single-test">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Running single test</a><a class="headerlink" href="#running-single-test" title="Link to this heading">¶</a></h3>
<p>Let run a convolution tests</p>
<p><code class="docutils literal notranslate"><span class="pre">TOT/health_exam&gt;</span> <span class="pre">TOT/verif/tools/run_test.py</span> <span class="pre">-P</span> <span class="pre">nv_small</span> <span class="pre">dc_24x33x55_5x5x55x25_int8_0</span> <span class="pre">-outdir</span> <span class="pre">dc_24x33x55_5x5x55x25_int8_output</span> <span class="pre">-wave</span> <span class="pre">-v</span> <span class="pre">nvdla_utb</span></code></p>
<p>Argument explanations:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-P nv_small</p></td>
<td><p>Running test on project NV_SMALL</p></td>
</tr>
<tr class="row-odd"><td><p>dc_24x33x55_5x5x55x25_int8_0</p></td>
<td><p>Select test source named
dc_24x33x55_5x5x55x25_int8_0</p></td>
</tr>
<tr class="row-even"><td><p>-outdir
dc_24x33x55_5x5x55x25_int8_output</p></td>
<td><p>Simulation will be run in
directory
dc_24x33x55_5x5x55x25_int8_output
will be</p></td>
</tr>
<tr class="row-odd"><td><p>-wave</p></td>
<td><p>Enable waveform dumping</p></td>
</tr>
<tr class="row-even"><td><p>-v nvdla_utb</p></td>
<td><p>Specify target testbench</p></td>
</tr>
</tbody>
</table>
<p>Wait for a while, when simulation is finished, following message will be
shown in the end of log:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">*******************************</span>
<span class="o">**</span>        <span class="n">TEST</span> <span class="n">PASS</span>          <span class="o">**</span>
<span class="o">*******************************</span>


<span class="n">PPPP</span>     <span class="n">A</span>     <span class="n">SSSSS</span>  <span class="n">SSSSS</span>
<span class="n">P</span>   <span class="n">P</span>   <span class="n">A</span> <span class="n">A</span>    <span class="n">S</span>      <span class="n">S</span>
<span class="n">PPPP</span>   <span class="n">AAAAA</span>   <span class="n">SSSSS</span>  <span class="n">SSSSS</span>
<span class="n">P</span>     <span class="n">A</span>     <span class="n">A</span>      <span class="n">S</span>      <span class="n">S</span>
<span class="n">P</span>     <span class="n">A</span>     <span class="n">A</span>  <span class="n">SSSSS</span>  <span class="n">SSSSS</span>
</pre></div>
</div>
<p>There are several files were generated under</p>
<p><code class="docutils literal notranslate"><span class="pre">TOT/health_exam/dc_24x33x55_5x5x55x25_int8_output</span></code></p>
<ol class="arabic simple">
<li><p>run_verdi.sh: which is used to kick-off Verdi to view simulation
waveform</p></li>
<li><p>testout: which contains output logs</p></li>
</ol>
</section>
<section id="running-a-list-of-tests">
<h3><a class="toc-backref" href="#id9" role="doc-backlink">Running a list of tests</a><a class="headerlink" href="#running-a-list-of-tests" title="Link to this heading">¶</a></h3>
<p>We can run a list of tests for wider health status check</p>
<p><code class="docutils literal notranslate"><span class="pre">TOT/health_examp&gt;TOT/verif/tools/run_plan.py</span> <span class="pre">-P</span> <span class="pre">nv_small</span> <span class="pre">-tp</span> <span class="pre">nv_small</span> <span class="pre">-atag</span> <span class="pre">protection</span> <span class="pre">-no_lsf</span> <span class="pre">-run_dir</span> <span class="pre">protection_tests</span> <span class="pre">-monitor</span></code></p>
<p>Argument explanations:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-P nv_small</p></td>
<td><p>Running test on project NV_SMALL</p></td>
</tr>
<tr class="row-odd"><td><p>-tp nv_small</p></td>
<td><p>Running tests in test plan
nv_small</p></td>
</tr>
<tr class="row-even"><td><p>-atag protection</p></td>
<td><p>Select tests which have been
tagged with “protection”</p></td>
</tr>
<tr class="row-odd"><td><p>-no_lsf</p></td>
<td><p>Use local CPU to run tests</p></td>
</tr>
<tr class="row-even"><td><p>-run_dir protection_tests</p></td>
<td><p>Output file will be run in
directory protection_tests</p></td>
</tr>
<tr class="row-odd"><td><p>-monitor</p></td>
<td><p>Continuously monitoring test
running status, until all
simulations are done or reach
maximum runtime</p></td>
</tr>
</tbody>
</table>
<p><em>*detail meanings of arguments could be found in both script self-contained help argument and later section</em> <a class="reference internal" href="#regression-tool-set">Regression Tool Set</a></p>
<p>Terminal will update tests status in a certain interval:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">Dir</span> <span class="o">=</span> <span class="n">TOT</span><span class="o">/</span><span class="n">health_exam</span><span class="o">/</span><span class="n">protection_tests</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="n">Test</span>                                    <span class="n">TB</span>                   <span class="n">Status</span>     <span class="n">Errinfo</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="n">pdp_8x8x32_1x1_int8_1</span>                   <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="n">pdp_7x9x10_3x3_int8</span>                     <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="n">sdp_8x8x32_bypass_int8_1</span>                <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="n">sdp_8x8x32_bypass_int8_0</span>                <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="n">sdp_4x22x42_bypass_int8</span>                 <span class="n">nvdla_utb</span>            <span class="n">RUNNING</span>
<span class="n">cdp_8x8x32_lrn3_int8_1</span>                  <span class="n">nvdla_utb</span>            <span class="n">RUNNING</span>
<span class="n">cdp_8x8x64_lrn9_int8</span>                    <span class="n">nvdla_utb</span>            <span class="n">RUNNING</span>
<span class="n">dc_24x33x55_5x5x55x25_int8_0</span>            <span class="n">nvdla_utb</span>            <span class="n">RUNNING</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
</pre></div>
</div>
<p>Wait for several minutes, all tests will be passed, and the final output
will be</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">Dir</span> <span class="o">=</span> <span class="n">TOT</span><span class="o">/</span><span class="n">health_exam</span><span class="o">/</span><span class="n">protection_tests</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="n">Test</span>                                    <span class="n">TB</span>                   <span class="n">Status</span>     <span class="n">Errinfo</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="n">pdp_8x8x32_1x1_int8_1</span>                   <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="n">pdp_7x9x10_3x3_int8</span>                     <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="n">sdp_8x8x32_bypass_int8_1</span>                <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="n">sdp_8x8x32_bypass_int8_0</span>                <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="n">sdp_4x22x42_bypass_int8</span>                 <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="n">cdp_8x8x32_lrn3_int8_1</span>                  <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="n">cdp_8x8x64_lrn9_int8</span>                    <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="n">dc_24x33x55_5x5x55x25_int8_0</span>            <span class="n">nvdla_utb</span>            <span class="n">PASS</span>
<span class="o">----------------------------------------------------------------------------------------------------</span>
<span class="n">TOTAL</span>    <span class="n">PASS</span>      <span class="n">FAILED</span>    <span class="n">RUNNING</span>   <span class="n">PENDING</span>   <span class="n">Passng</span> <span class="n">Rate</span>
<span class="mi">8</span>        <span class="mi">8</span>         <span class="mi">0</span>         <span class="mi">0</span>         <span class="mi">0</span>         <span class="mf">100.00</span><span class="o">%</span>
</pre></div>
</div>
<p>Simulation log and result could be found under
<code class="docutils literal notranslate"><span class="pre">TOT/health_exam/protection_tests/nvdla_utb</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>protection_tests
`-- nvdla_utb
    |-- cdp_8x8x32_lrn3_int8_1
    |-- cdp_8x8x64_lrn9_int8
    |-- dc_24x33x55_5x5x55x25_int8_0
    |-- pdp_7x9x10_3x3_int8
    |-- pdp_8x8x32_1x1_int8_1
    |-- sdp_4x22x42_bypass_int8
    |-- sdp_8x8x32_bypass_int8_0
    `-- sdp_8x8x32_bypass_int8_1
</pre></div>
</div>
</section>
</section>
<section id="verification-suite">
<h2><a class="toc-backref" href="#id10" role="doc-backlink">Verification Suite</a><a class="headerlink" href="#verification-suite" title="Link to this heading">¶</a></h2>
<p>NVDLA verification suite contains test bench, test plan and test suites.</p>
<p>Verification related files could be found under <code class="docutils literal notranslate"><span class="pre">TOT/verif</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>verif
|-- regression
|   `-- testplans
|-- testbench
|   |-- trace_generator
|   `-- trace_player
|--&lt;some other directories&gt;
`-- tests
    |-- trace_tests
    `-- uvm_tests
</pre></div>
</div>
<section id="test-bench-architecture">
<h3><a class="toc-backref" href="#id11" role="doc-backlink">Test Bench Architecture</a><a class="headerlink" href="#test-bench-architecture" title="Link to this heading">¶</a></h3>
<p>NVDLA verification adopts coverage driven methodology which relies on
constrained random stimulus.</p>
<p>Test bench also need to support direct tests for other considerations
which require fixed invariant stimulus:</p>
<ol class="arabic simple">
<li><p>Protection tests for code commit quality check.</p></li>
<li><p>Sanity tests for fast flushing plain and simple bugs.</p></li>
<li><p>Tests from real application (real network).</p></li>
</ol>
<p>Simulation flow is divided into two phases: stimulus recording (trace
generation) and stimulus playing (trace playing). There are independent
executables for different phases.</p>
<ol class="arabic simple">
<li><p>Trace generation: a trace generator response for generating traces
from constrained random tests. It contains with random constraints
and random test suite.</p></li>
<li><p>Trace playing: a trace player response for driving trace to DUT,
checking DUT correct behavior, and collecting coverages. It contains
with agents for interacting with DUT, reference mode for correct
behavior checking and coverage model for verification completeness
measurement.</p></li>
</ol>
<section id="trace-generator">
<h4>Trace generator<a class="headerlink" href="#trace-generator" title="Link to this heading">¶</a></h4>
<p><strong>To be done</strong></p>
</section>
<section id="trace-player">
<h4>Trace player<a class="headerlink" href="#trace-player" title="Link to this heading">¶</a></h4>
<p><strong>To be done</strong></p>
</section>
</section>
<section id="test-plan">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Test Plan</a><a class="headerlink" href="#test-plan" title="Link to this heading">¶</a></h3>
<p>Test plan record tests and corresponding configurations for regression.
There is one test plan for one configuration project. Test plan file
location is:
<code class="docutils literal notranslate"><span class="pre">TOT/verif/regression/testplans</span></code>.</p>
<p>Currently, this only one valid test plan: <code class="docutils literal notranslate"><span class="pre">NV_SMALL</span></code>.</p>
<section id="test-levels">
<h4>Test Levels<a class="headerlink" href="#test-levels" title="Link to this heading">¶</a></h4>
<p>One test plan contains several test levels:</p>
<ul class="simple">
<li><p>Level 0: Pass through cases which are based read data from memory and
write to memory without function operation. Basic function tests.
Most of protection tests will be select from this level.</p></li>
<li><p>Level 1: Common function case. Basic features such as major ASIC data
path, special memory alignments, tests are single layer tests.</p></li>
<li><p>Level 2: Corner cases, for example, extreme small cube size (1x1x1 in
width,height,channel), maximum width cube size (8192x1x1 in
width,height,channel).</p></li>
<li><p>Level 3: reserved for multi-layer cases, run multiple layers on the
same hardware pipelines.</p></li>
<li><p>Level 4: reserved for multi-scenario, running independent hardware
pipelines (convolution, pdp, cdp) in the same time.</p></li>
<li><p>Level 5: reserved for perf tests</p></li>
<li><p>Level 6: reserved for power tests</p></li>
<li><p>Level 7: reserved for time-consumed tests</p></li>
<li><p>Level 8: reserved for real network cases</p></li>
<li><p>Level 9: reserved</p></li>
<li><p>Level 10: random tests for single scenario</p></li>
<li><p>Level 11: random tests for multi scenario</p></li>
</ul>
<p>Level 0 to 8 are considered as direct tests, level 10 to 11 are
considered as random tests. There are dedicated test list files for each
test level.</p>
</section>
<section id="associating-tests">
<h4>Associating Tests<a class="headerlink" href="#associating-tests" title="Link to this heading">¶</a></h4>
<p>Test plan provides a method named add_test to associate tests with test
plan, in each test, there are 5 fields:</p>
<ul class="simple">
<li><p>Name: test source name</p></li>
<li><p>Tags: tags for test selection</p></li>
<li><p>Args: required arguments for test simulation, arguments will be
documented in test bench and</p></li>
<li><p>Config: target test bench, currently, there is only one valid test
bench setting: nvdla_utb which stands for NVDLA Unit Test bench.</p></li>
<li><p>Module: use to distinguish different types of tests</p></li>
<li><p>Desc: test description</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">add_test</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;dc_24x33x55_5x5x55x25_int8_0&#39;</span><span class="p">,</span>
         <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;L0&#39;</span><span class="p">,</span><span class="s1">&#39;cc&#39;</span><span class="p">,</span><span class="s1">&#39;protection&#39;</span><span class="p">],</span>
         <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">FIXED_SEED_ARG</span><span class="p">,</span> <span class="n">DISABLE_COMPARE_ALL_UNITS_SB_ARG</span><span class="p">],</span>
         <span class="n">config</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;nvdla_utb&#39;</span><span class="p">],</span>
         <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;&#39;&#39;copied from cc_small_full_feature_5, kernel stride 4x3, unpacked, pad L/R/T/B, clip truncate 4, full weight&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="test-suite">
<h3><a class="toc-backref" href="#id13" role="doc-backlink">Test Suite</a><a class="headerlink" href="#test-suite" title="Link to this heading">¶</a></h3>
<p>There are two kinds of tests:</p>
<ol class="arabic simple">
<li><p>Direct tests: direct tests are in trace format. Test source files are
under TOT/verif/tests/trace. Trace tests are organized by
configuration project. Trace tests for NV_SMALL configuration is
under <code class="docutils literal notranslate"><span class="pre">TOT/verif/tests/trace_tests/nv_small</span></code>.</p></li>
<li><p>Random tests: random tests are in UVM test format. Random tests are
expected to be configuration independent. Random test directory is
<code class="docutils literal notranslate"><span class="pre">TOT/verif/tests/trace_tests/uvm_tests</span></code>.</p></li>
</ol>
<p><em>*For now, only trace tests are ready.</em></p>
<section id="test-naming">
<h4>Test naming<a class="headerlink" href="#test-naming" title="Link to this heading">¶</a></h4>
<p>Test naming is convenience for fast understanding test scenarios. There
are several portions in test name:</p>
<p>&lt;MAJOR_FUNCTIONS&gt;_&lt;DIMEMSION_SETTINGS&gt;_&lt;SUPPLEMENTARY_INFO&gt;_&lt;MINOR_FUNCTIONS&gt;_&lt;PRECISION&gt;_&lt;INDEX&gt;</p>
<section id="portion-explanation">
<h5>Portion Explanation<a class="headerlink" href="#portion-explanation" title="Link to this heading">¶</a></h5>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Portion</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Necessity</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MAJOR_FUNCTIONS</p></td>
<td><p>Major hardware
pipelines. Possible
values:</p>
<ul class="simple">
<li><p>DC: direct
convolution, input
is feature cube
format</p></li>
<li><p>IMG: direct
convolution, input
is image format</p></li>
<li><p>WINO: Winograd
convolution, input
is feature cube
format</p></li>
</ul>
</td>
<td><p>Must have</p></td>
</tr>
<tr class="row-odd"><td><p>DIMEMSION_SETTINGS</p></td>
<td><p>Cube dimensions, for
convolution tests,
there are two cubes,
one is for data, one
is for weight.
Dimension orders.</p>
<ul class="simple">
<li><p>For data: width,
height, channel</p></li>
<li><p>For weight: width,
height, channel,
kernel</p></li>
</ul>
</td>
<td><p>Must have</p></td>
</tr>
<tr class="row-even"><td><p>SUPPLEMENTARY_INFO</p></td>
<td><p>Supplementary
information, for
examples:</p>
<ul class="simple">
<li><p>In image
convolution, image
format</p></li>
<li><p>In SDP, there are
multiple operation
units like BS/BN.</p></li>
<li><p>In PDP, pooling
stride settings</p></li>
</ul>
</td>
<td><p>Optional</p></td>
</tr>
<tr class="row-odd"><td><p>MINOR_FUNCTIONS</p></td>
<td><p>Minor functions
within major hardware
pipeline. For
example, in
convolution pipeline,
there are weight
compression, dilation
etc.</p></td>
<td><p>Optional</p></td>
</tr>
<tr class="row-even"><td><p>PRECISION</p></td>
<td><p>Specify working
precision.</p></td>
<td><p>Must have</p></td>
</tr>
<tr class="row-odd"><td><p>INDEX</p></td>
<td><p>Some tests share the
same configuration
but different memory
surface, use index to
distinguish those
tests</p></td>
<td><p>Optional</p></td>
</tr>
</tbody>
</table>
</section>
<section id="examples">
<h5>Examples<a class="headerlink" href="#examples" title="Link to this heading">¶</a></h5>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Test name</p></th>
<th class="head"><p>Scenario description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>dc_24x33x55_5x5x55x25_int8_0</p></td>
<td><p>direct convolution, input feature
cube dimension is 24x33x55
(width, height, channel), weight
cube dimension is 5x5x55x25
(width, height, channel, kernel),
precision is INT8</p></td>
</tr>
<tr class="row-odd"><td><p>sdp_3x3x33_bs_int8_reg_0</p></td>
<td><p>Single data processing, input
feature cube dimension is 3x3x33
(width, height, channel), using
BS operation unit, operand from
register, precision is INT8</p></td>
</tr>
<tr class="row-even"><td><p>pdp_8x8x64_2x2_int8</p></td>
<td><p>Pooling, input feature cube
dimension is 8x8x64 (width,
height, channel), precision is
INT8</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="test-format">
<h4>Test Format<a class="headerlink" href="#test-format" title="Link to this heading">¶</a></h4>
<section id="trace-test-format">
<h5>Trace Test format<a class="headerlink" href="#trace-test-format" title="Link to this heading">¶</a></h5>
<p>In unit test bench, trace player only receives tests in trace format.
Trace test is the source format of direct tests and the inter-media
outputs of random tests.</p>
<p>Trace test is not only used in unit RTL verification environment, but
also could be reused in other environments like system verification,
CMOD verification, FPGA validation, and silicon bringup.</p>
<p>Trace format supports following cases:</p>
<ol class="arabic simple">
<li><p>Single layer case: only one hardware pipeline and only one
configuration group will be exercised during simulation.</p></li>
<li><p>Multi-layer case: configuration group will be alternative used during
simulation within the same hardware pipeline.</p></li>
<li><p>Multi-resource cases: one hardware pipeline which consists of
multiple hardware resource. For example, a fused
convolution-batch_normlization-relu-pooling layer could be executed
in single hardware layer, this hardware layer requires several
computational resources convolution, SDP and PDP.</p></li>
<li><p>Multi-scenario case: multiple independent hardware layer
configuration could be presented in the same test.</p></li>
</ol>
<p>Trace stores the stimulus of simulation. There are two types of
stimulus, and there is dedicated format to support each type of
stimulus:</p>
<ol class="arabic simple">
<li><p>Register configuration, stored in config file (file name is *.cfg).
One test only has one configuration file.</p></li>
<li><p>Memory data, stored in data files (file name is *.dat). One test has
at least one memory data file for input data. One test could have
more than one data file, for example, in convolution tests, there is
one file for input image/feature cube and one file for weight.</p></li>
</ol>
<p>Trace file also provide result checking methods:</p>
<ol class="arabic simple">
<li><p>Golden CRC, which is represented in one configuration command.</p></li>
<li><p>Golden output memory surface, which is represented in one
configuration command and an associated data file.</p></li>
</ol>
<section id="configuration-file-format">
<h6>Configuration File Format<a class="headerlink" href="#configuration-file-format" title="Link to this heading">¶</a></h6>
<p>There are 9 types of configuration commands:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Name</strong></p></th>
<th class="head"><p><strong>Description</strong></p></th>
<th class="head"><p><strong>Syntax</strong></p></th>
<th class="head"><p><strong>Use case</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>reg_write</p></td>
<td><p>Write data to
specific DUT
register</p></td>
<td><p>reg_write(reg_n
ame,
reg_value);</p></td>
<td><p>Fundamental
operation for
register
configuration</p></td>
</tr>
<tr class="row-odd"><td><p>reg_read_expect
ed</p></td>
<td><p>Read data from
specific DUT
register,
compare with
expected value</p></td>
<td><p>reg_read_expect
ed(addr,
expected_data);</p></td>
<td><p>For some
special cases
like register
accessing tests</p></td>
</tr>
<tr class="row-even"><td><p>reg_read</p></td>
<td><p>Read data from
specific DUT
register</p></td>
<td><p>reg_read(reg_na
me,
return_value);</p></td>
<td><p>For specific
cases which may
need to do
post-processing
on read return
value.</p></td>
</tr>
<tr class="row-odd"><td><p>sync_notify</p></td>
<td><p>Specified
player
sequencer will
send out
synchronization
event</p></td>
<td><p>sync_notify(tar
get_resource,
sync_id);</p></td>
<td><p>CC pipeline,
OP_EN
configuration
order,
CACC-&gt;CMAC-&gt;CSC
.</p></td>
</tr>
<tr class="row-even"><td><p>sync_wait</p></td>
<td><p>Specified
player
sequencer will
wait on
synchronization
event</p></td>
<td><p>sync_wait(targe
t_resource,
sync_id);</p></td>
<td><p>CC pipeline,
OP_EN
configuration
order,
CACC-&gt;CMAC-&gt;CSC
.</p></td>
</tr>
<tr class="row-odd"><td><p>intr_notify</p></td>
<td><p>Monitor DUT
interrupt,
catch and clear
interrupt and
send
synchronization
event.</p>
<p>There could be
multiple
intr_notify,
all those
intr_notify are
processed
sequentially.
The processing
order is the
same as
commands’ line
order in
configuration
file.</p>
</td>
<td><p>intr_notify(int
r_id,
sync_id); //
notify when
specific
interrupt fired</p></td>
<td><p>Hardware layer
complete
notification,
informing test
bench that test
is ended.</p>
<p>Multi-layer
test which is
presumed
containing
layer 0 ~ N,
for n &gt;1
layers, they
shall wait for
interrupts.</p>
</td>
</tr>
<tr class="row-even"><td><p>poll</p></td>
<td><p>Continues poll
register/field
value from DUT,
until one of
the following
conditions are
met:</p>
<ol class="arabic simple">
<li><p>Equal,
polled value
is equal to
expected
value</p></li>
<li><p>Greater,
polled value
is greater
than
expected
value</p></li>
<li><p>Less, polled
value is
less than
expected
value</p></li>
<li><p>Not equal,
polled value
is not equal
to expected
value</p></li>
<li><p>Not greater,
polled value
is not
greater than
expected
value</p></li>
<li><p>Not less,
polled value
is not less
than
expected
value</p></li>
</ol>
</td>
<td><p>poll_field_equa
l(target_resour
ce,
register_name,
field_name,
expected_value)
;</p>
<p>poll_reg_equal(
target_resource
,
register_name,
expected_value)
;</p>
<p>poll_field_grea
ter(target_reso
urce,
register_name,
field_name,
expected_value)
;</p>
<p>poll_reg_less(t
arget_resource,
register_name,
expected_value)
;</p>
<p>poll_field_nt_
greater(taget_
resource,
register_name,
field_name,
expected_value)
;</p>
<p>poll_reg_not_le
ss(target_resou
rce,
register_name,
expected_value)
;</p>
</td>
<td><p>Convolution
case, wait
until CBUF
flush has done</p></td>
</tr>
<tr class="row-odd"><td><p>check</p></td>
<td><p>Invoke player
result checking
method.</p>
<p>When test bench
works in
RTL/CMOD cross
checking mode,
neither golden
CRC nor golden
files are
necessary in
this case.
Method
check_nothing()
shall be added
to trace file
to indicated
test end event.</p>
</td>
<td><p>check_crc(syn_
id,
memory_type,
base_address,
size,
golden_crc_valu
e);</p>
<p>check_file(sync
_id,
memory_type,
base_address,
size,
“golden_file_na
me”);</p>
<p>check_nothing(s
ync_id);</p>
</td>
<td><p>CRC check for
no CMOD
simulation
(usually
generated by
arch/inherit
from previous
project/eyeball
gilded)</p>
<p>Golden memory
result check
for no CMOD
simulation
(usually
generated by
arch/inherit
from previous
project/eyeball
gilded)</p>
</td>
</tr>
<tr class="row-even"><td><p>mem</p></td>
<td><p>Load memory
from file.</p>
<p>Initialize
memory by
pattern.</p>
</td>
<td><p>mem_load(ram_ty
pe,
base_addr,
file_path); //
file_path shall
be enclosed by
“”</p>
<p>mem_init(ram_ty
pe,
base_addr,
size, pattern);</p>
</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>*Some functions are not supported yet.</strong></p>
</section>
<section id="memory-surface-file-format">
<h6>Memory Surface File Format<a class="headerlink" href="#memory-surface-file-format" title="Link to this heading">¶</a></h6>
<p>When mem_load command is shown in configuration file, test bench will
load corresponding file into memory model.</p>
<p>Memory surface format is in memory mapped form. The basic data group is
call packet, each packet item contains one address offset field, one
size field and one payload field. It’s used to store data in payload
field to memory space starting from address (base + offset).</p>
<p>The string describing one packet item must be kept in one single line.</p>
<p>Payload byte must be separated by space, and payload size shall not be
no larger than 32 for readability consideration.</p>
<p>Different packets shall be joined by comma “,”.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>

<span class="p">{</span><span class="n">offset</span><span class="p">:</span><span class="mh">0x20</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="n">payload</span><span class="p">:</span><span class="mh">0x00</span> <span class="mh">0x10</span> <span class="mh">0x20</span> <span class="mh">0x30</span><span class="p">}</span> <span class="p">,</span>

<span class="p">{</span><span class="n">offset</span><span class="p">:</span><span class="mh">0x60</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="n">payload</span><span class="p">:</span><span class="mh">0x00</span> <span class="mh">0x10</span> <span class="mh">0x20</span> <span class="mh">0x30</span><span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
<p>For packet <code class="docutils literal notranslate"><span class="pre">{offset:0x20,</span> <span class="pre">size:4,</span> <span class="pre">payload:0x00</span> <span class="pre">0x10</span> <span class="pre">0x20</span> <span class="pre">0x30}</span></code>, data
in memory layout is</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>Address</p></td>
<td><p>0x20</p></td>
<td><p>0x21</p></td>
<td><p>0x22</p></td>
<td><p>0x23</p></td>
</tr>
<tr class="row-even"><td><p>Value</p></td>
<td><p>0x00</p></td>
<td><p>0x10</p></td>
<td><p>0x20</p></td>
<td><p>0x30</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="random-test-format">
<h5>Random Test Format<a class="headerlink" href="#random-test-format" title="Link to this heading">¶</a></h5>
<p><strong>To be done</strong></p>
</section>
</section>
</section>
</section>
<section id="regression-tool-set">
<h2><a class="toc-backref" href="#id14" role="doc-backlink">Regression Tool Set</a><a class="headerlink" href="#regression-tool-set" title="Link to this heading">¶</a></h2>
<p>There is a tool set for:</p>
<ol class="arabic simple">
<li><p>Running single test simulation.</p></li>
<li><p>Running a test plan, tests associated with specific test plan will be
running. It could be considered as one round of regression.</p></li>
<li><p>Examining single round regression result and generate metrics for
whole project lasting time.</p></li>
</ol>
<section id="running-a-single-test">
<h3><a class="toc-backref" href="#id15" role="doc-backlink">Running a Single Test</a><a class="headerlink" href="#running-a-single-test" title="Link to this heading">¶</a></h3>
<p>There is a script TOT/verif/tools/run_test.py for running single test,
the most common usages are:</p>
<p><code class="docutils literal notranslate"><span class="pre">&gt;TOT/verif/tools/run_test.py</span> <span class="pre">-P</span> <span class="pre">&lt;project_name&gt;</span> <span class="pre">-mod</span> <span class="pre">&lt;test_module&gt;</span>
<span class="pre">&lt;trace_test_name&gt;</span> <span class="pre">-outdir</span> <span class="pre">&lt;output_directory&gt;</span> <span class="pre">-v</span> <span class="pre">nvdla_utb</span></code></p>
<section id="argument-explanations">
<h4>Argument Explanations:<a class="headerlink" href="#argument-explanations" title="Link to this heading">¶</a></h4>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-P &lt;project_name&gt;</p></td>
<td><p>Project name which is specified
in tree.make</p></td>
</tr>
<tr class="row-odd"><td><p>-mod &lt;test_module&gt;</p></td>
<td><p>Specifying test kind, if it is
not specified, will select trace
test by default</p></td>
</tr>
<tr class="row-even"><td><p>&lt;trace_test_name&gt;</p></td>
<td><p>Test name which could be found
under project related trace
directory</p></td>
</tr>
<tr class="row-odd"><td><p>-outdir &lt;output_directory&gt;</p></td>
<td><p>Specifying working directory,
temporal files and log will be
generated in output_directory, if
outdir has not been specified,
current directory will be used as
working directory.</p></td>
</tr>
<tr class="row-even"><td><p>-v nvdla_utb</p></td>
<td><p>Specifying test bench, for now,
only unit test bench is
available, so nvdla_utb is the
only valid argument</p></td>
</tr>
</tbody>
</table>
<p>Please run <code class="docutils literal notranslate"><span class="pre">run_test.py</span></code> with <code class="docutils literal notranslate"><span class="pre">-help</span></code> argument for more arguments and their
usages.</p>
</section>
<section id="examining-result">
<h4>Examining Result<a class="headerlink" href="#examining-result" title="Link to this heading">¶</a></h4>
<p>There are several files were generated during simulation, three files
need to be paid more attention:</p>
<ol class="arabic simple">
<li><p>run_trace_player.sh: a script for rerunning test</p></li>
<li><p>run_verdi.sh: a script for kicking off Verdi to view waveforms</p></li>
<li><p>testout, log file</p></li>
<li><p>STATUS, file records test running status, there are several status:</p>
<ol class="arabic simple">
<li><p>RUNNING, test is still in running.</p></li>
<li><p>FAIL, test result is failure.</p></li>
<li><p>PASS, test result is pass.</p></li>
</ol>
</li>
</ol>
</section>
</section>
<section id="running-a-test-plan">
<h3><a class="toc-backref" href="#id16" role="doc-backlink">Running a Test Plan</a><a class="headerlink" href="#running-a-test-plan" title="Link to this heading">¶</a></h3>
<p>There is a script TOT/verif/tools/run_plan.py for running tests within a
test plan.</p>
<p><code class="docutils literal notranslate"><span class="pre">&gt;TOT/verif/tools/run_plan.py</span> <span class="pre">--test_plan</span> <span class="pre">&lt;TEST_PLAN_NAME&gt;</span> <span class="pre">-P</span> <span class="pre">&lt;PROJECT&gt;</span>
<span class="pre">-atag</span> <span class="pre">&lt;and_tags&gt;</span> <span class="pre">-otag</span> <span class="pre">&lt;or_tags&gt;</span> <span class="pre">-run_dir</span> <span class="pre">&lt;RUN_DIR&gt;</span> <span class="pre">-no_lsf</span> <span class="pre">-monitor</span></code></p>
<section id="argument-explanations-1">
<span id="id1"></span><h4>Argument Explanations:<a class="headerlink" href="#argument-explanations-1" title="Link to this heading">¶</a></h4>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>–test_plan &lt;TEST_PLAN_NAME&gt;</p></td>
<td><p>Test plan file name, without
‘.py’ suffix.</p></td>
</tr>
<tr class="row-odd"><td><p>–test_plan &lt;TEST_PLAN_NAME&gt;</p></td>
<td><p>Project name which has been
specified in tree.make</p></td>
</tr>
<tr class="row-even"><td><p>-atag &lt;and_tags&gt;</p></td>
<td><p>means AND tags, will select tests
which has all tags specified by
atag</p></td>
</tr>
<tr class="row-odd"><td><p>-otag &lt;or_tags&gt;</p></td>
<td><p>means OR tags, will select tests
which contain at least one of
tags specified by otag</p></td>
</tr>
<tr class="row-even"><td><p>-ntag &lt;not_tags&gt;</p></td>
<td><p>means NOT tags, will select tests
which don’t not contain any tags
specified by ntag</p></td>
</tr>
<tr class="row-odd"><td><p>-run_dir &lt;RUN_DIR&gt;</p></td>
<td><p>Specify working directory</p></td>
</tr>
<tr class="row-even"><td><p>-no_lsf</p></td>
<td><p>will run test on local CPU</p></td>
</tr>
<tr class="row-odd"><td><p>-monitor</p></td>
<td><p>will continuously monitoring test
running status, until all
simulations are done or reach
maximum runtime</p></td>
</tr>
</tbody>
</table>
<p>Please run <code class="docutils literal notranslate"><span class="pre">run_plan.py</span></code> with <code class="docutils literal notranslate"><span class="pre">-help</span></code> argument for more arguments and their
usages.</p>
<p>Simulation results could be found under <strong>run_dir</strong>. There are 2
hierarchy levels under <code class="docutils literal notranslate"><span class="pre">run_dir</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>RUN_DIR
|-- &lt;TEST_BENCH_0&gt;
|   |-- TEST_A
|   |-- TEST_B
|   |-- …
|   `-- TEST_G
`-- &lt;TEST_BENCH_1&gt;
    |-- TEST_H
    |-- …
    `-- TEST_N
</pre></div>
</div>
<ol class="arabic simple">
<li><p>The first level is test bench level. If a plan contains multiple test
benches, there will be dedicated directory for each test bench</p></li>
<li><p>The second level is test level. Under test bench level, there are
several test directories. Each directory contains temporal and result
files for one test simulation.</p></li>
</ol>
</section>
<section id="examining-result-1">
<span id="id2"></span><h4>Examining result<a class="headerlink" href="#examining-result-1" title="Link to this heading">¶</a></h4>
<p>There is a script TOT/verif/tools/run_report.py for monitoring
regression status, the most common usages are:</p>
<p>&gt;TOT/verif/tools/run_report.py -run_dir &lt;regression_run_directory&gt;
-monitor_timeout MONITOR_TIMEOUT -monitor</p>
<p>Please run run_test.py with -help argument for more arguments and their
usages.</p>
</section>
</section>
<section id="generating-reporting-metrics">
<h3><a class="toc-backref" href="#id17" role="doc-backlink">Generating Reporting Metrics</a><a class="headerlink" href="#generating-reporting-metrics" title="Link to this heading">¶</a></h3>
<p><strong>To be done</strong></p>
<p>Here is the end of <strong>NVDLA Verification Suite User Guide</strong>.</p>
</section>
</section>
</section>


        </div>
        <div class="col-xs-12 col-md-3">
          
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../../contents.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">NVDLA Verification Suite User Guide</a><ul>
<li><a class="reference internal" href="#preparation">Preparation</a><ul>
<li><a class="reference internal" href="#acronym">Acronym</a></li>
<li><a class="reference internal" href="#setup-tree-make-and-build-tree">Setup tree.make and Build tree</a></li>
</ul>
</li>
<li><a class="reference internal" href="#quick-start">Quick Start</a><ul>
<li><a class="reference internal" href="#running-single-test">Running single test</a></li>
<li><a class="reference internal" href="#running-a-list-of-tests">Running a list of tests</a></li>
</ul>
</li>
<li><a class="reference internal" href="#verification-suite">Verification Suite</a><ul>
<li><a class="reference internal" href="#test-bench-architecture">Test Bench Architecture</a><ul>
<li><a class="reference internal" href="#trace-generator">Trace generator</a></li>
<li><a class="reference internal" href="#trace-player">Trace player</a></li>
</ul>
</li>
<li><a class="reference internal" href="#test-plan">Test Plan</a><ul>
<li><a class="reference internal" href="#test-levels">Test Levels</a></li>
<li><a class="reference internal" href="#associating-tests">Associating Tests</a></li>
</ul>
</li>
<li><a class="reference internal" href="#test-suite">Test Suite</a><ul>
<li><a class="reference internal" href="#test-naming">Test naming</a><ul>
<li><a class="reference internal" href="#portion-explanation">Portion Explanation</a></li>
<li><a class="reference internal" href="#examples">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#test-format">Test Format</a><ul>
<li><a class="reference internal" href="#trace-test-format">Trace Test format</a><ul>
<li><a class="reference internal" href="#configuration-file-format">Configuration File Format</a></li>
<li><a class="reference internal" href="#memory-surface-file-format">Memory Surface File Format</a></li>
</ul>
</li>
<li><a class="reference internal" href="#random-test-format">Random Test Format</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#regression-tool-set">Regression Tool Set</a><ul>
<li><a class="reference internal" href="#running-a-single-test">Running a Single Test</a><ul>
<li><a class="reference internal" href="#argument-explanations">Argument Explanations:</a></li>
<li><a class="reference internal" href="#examining-result">Examining Result</a></li>
</ul>
</li>
<li><a class="reference internal" href="#running-a-test-plan">Running a Test Plan</a><ul>
<li><a class="reference internal" href="#argument-explanations-1">Argument Explanations:</a></li>
<li><a class="reference internal" href="#examining-result-1">Examining result</a></li>
</ul>
</li>
<li><a class="reference internal" href="#generating-reporting-metrics">Generating Reporting Metrics</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="scalability.html"
                          title="previous chapter">Scalability parameters and ConfigROM</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="../../sw/contents.html"
                          title="next chapter">Software Manual</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/hw/v2/verif_guide.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
        </div>
      </div>
    </div>
  </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <div class="container">
      <div class="row">
      <h3>Navigation</h3>
      <ul>
        <li class="right first">
          <a href="../../sw/contents.html" title="Software Manual"
             >next</a></li>
        <li class="right">
          <a href="scalability.html" title="Scalability parameters and ConfigROM"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">NVDLA Open Source Project</a>&#187;</li>
        <li class="nav-item nav-item-1"><a href="../../contents.html">Documentation</a>&#187;</li>
          <li class="nav-item nav-item-2"><a href="../contents.html" >Hardware Manual</a>&#187;</li> 
      </ul>
      </div>
      </div>
    </div>
<div class="footer" role="contentinfo">
<div class="container">
<div class="row">
&#169; <a
href="../../copyright.html">Copyright</a> 2018 - 2026, NVIDIA Corporation.
<a href="https://www.nvidia.com/object/legal_info.html">Legal Information.</a>
<a href="https://www.nvidia.com/object/privacy_policy.html">Privacy Policy.</a>
Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
</div>
</div>
</div>
<script type="text/javascript">_satellite.pageBottom();</script>
  </body>
</html>